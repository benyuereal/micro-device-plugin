# Micro GPU Device Plugin for Kubernetes

## æ¦‚è¿°
è¿™æ˜¯ä¸€ä¸ªæ”¯æŒå¤šGPUèµ„æºé™åˆ¶çš„Kubernetesè®¾å¤‡æ’ä»¶ï¼Œç‰¹åˆ«ä¼˜åŒ–äº†å¯¹NVIDIA MIGè®¾å¤‡çš„æ”¯æŒã€‚å®ƒèƒ½å¤Ÿåœ¨Kubernetesé›†ç¾¤ä¸­è‡ªåŠ¨å‘ç°ã€ç®¡ç†å’Œåˆ†é…GPUèµ„æºï¼ŒåŒ…æ‹¬å®Œæ•´çš„GPUè®¾å¤‡å’ŒMIGåˆ†åŒºã€‚

## æ ¸å¿ƒç‰¹æ€§
- âœ… å®Œæ•´çš„GPUè®¾å¤‡å‘ç°ä¸ç®¡ç†
- âœ… NVIDIA MIGè®¾å¤‡æ”¯æŒï¼ˆè‡ªåŠ¨åˆ†åŒºä¸é…ç½®ï¼‰
- âœ… è®¾å¤‡å¥åº·æ£€æŸ¥ä¸ç›‘æ§
- â›”ï¸ CDIï¼ˆContainer Device Interfaceï¼‰æ”¯æŒ
- âœ… èµ„æºå›æ”¶ä¸è‡ªåŠ¨æ¸…ç†æœºåˆ¶

## å‰ææ¡ä»¶
### 1. Kubernetes é›†ç¾¤
- Kubernetes 1.20+ ç‰ˆæœ¬
- kubectl é…ç½®å®Œæˆ

### 2 Containerd é…ç½®
åœ¨ `/etc/containerd/config.toml` ä¸­æ·»åŠ ï¼š

```toml
      [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
          runtime_type = "io.containerd.runc.v2"
          privileged_without_host_devices = false
          [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
            BinaryName = "/usr/bin/nvidia-container-runtime"
```
### 3 runclassé…ç½®
```yaml
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia  # æŒ‡å‘ nvidia-container-runtime
```

### 4. **GPU MIG è®¾ç½®**:
```yaml
### å¯ç”¨mig
sudo nvidia-smi -mig 1
### åˆ›å»º MIG è®¾å¤‡ (ä¾‹å¦‚ 3g.20gb é…ç½®)
sudo nvidia-smi mig -cgi 9 -C
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### éƒ¨ç½²è®¾å¤‡æ’ä»¶
```yaml
kubectl apply -f manifests/daemonset.yaml
```

### éªŒè¯éƒ¨ç½²
```shell
kubectl get pods -n kube-system -l app=micro-device-plugin

kubectl logs -n kube-system -l app=micro-device-plugin --tail=50
```

### æµ‹è¯•ç¤ºä¾‹
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nvidia-test-pod
spec:
  runtimeClassName: nvidia
  restartPolicy: Never
  containers:
    - name: test-container
      image: nvcr.io/nvidia/pytorch:24.05-py3
      imagePullPolicy: IfNotPresent
      # å…³é”®ä¿®æ”¹ï¼šå¯åŠ¨æ— é™å¾ªç¯å‘½ä»¤
      command: ["/bin/sh", "-c"]
      args: ["while true; do sleep 3600; done"]  # æ¯å°æ—¶å”¤é†’ä¸€æ¬¡çš„æ°¸ä¹…å¾ªç¯
      resources:
        limits:
          nvidia.com/microgpu: 1
```

### éƒ¨ç½²æµ‹è¯•åº”ç”¨ï¼š

```shell

kubectl apply -f deployment/nvidia-test-pod.yaml
kubectl describe pod nvidia-test-pod
kubectl logs nvidia-test-pod --tail=-1
kubectl exec -it nvidia-test-pod -- sh

```

## ğŸ“Š åŠŸèƒ½ç‰¹æ€§
- æ”¯æŒ NVIDIA GPU å’Œ MIG è®¾å¤‡ç®¡ç†
- è‡ªåŠ¨å¥åº·æ£€æŸ¥å’Œè®¾å¤‡å›æ”¶
- CDI è®¾å¤‡æ³¨å…¥æ”¯æŒ
- æ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦ä¼˜åŒ–
- å¤šå®ä¾‹ GPU èµ„æºåˆ‡åˆ†

## ğŸ›  æ„å»ºä¸éƒ¨ç½²


```shell
docker build -t your-registry/micro-device-plugin:v1.0.0 .
docker push your-registry/micro-device-plugin:v1.0.0
```

## éƒ¨ç½²åˆ°kubernetes

```shell
kubectl apply -f manifests/daemonset.yaml
```

## ğŸ”§ é…ç½®é€‰é¡¹
| ç¯å¢ƒå˜é‡ | é»˜è®¤å€¼            | æè¿° |
|---------|----------------|------|
| `ENABLE_MIG` | `true`         | å¯ç”¨ MIG ç®¡ç† |
| `MIG_PROFILE` | `3g.20gb`      | MIG åˆ‡åˆ†é…ç½® |
| `MIG_INSTANCE_COUNT` | `0`            | MIG å®ä¾‹æ•°é‡ (0=è‡ªåŠ¨è®¡ç®—) |
| `SKIP_CONFIGURED` | `true`         | è·³è¿‡å·²é…ç½®çš„ MIG è®¾å¤‡ |
| `CDI_ENABLED` | `false`        | å¯ç”¨ CDI è®¾å¤‡æ³¨å…¥ |
| `CDI_PREFIX` | `micro.device` | CDI è®¾å¤‡å‰ç¼€ |